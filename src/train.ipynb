{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import jieba\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from utils import DATA_TEXT_SEQUENCES_PATH, DATA_LABELS_PATH\n",
    "from utils import DATA_W2V_VECTOR_PATH, DATA_W2V_META_PATH\n",
    "from utils import CustomIterator\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 4 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 12:36:11.425837: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-11 12:36:13.896066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 559 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:18:00.0, compute capability: 8.6\n",
      "2022-04-11 12:36:13.897171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 8550 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:3b:00.0, compute capability: 8.6\n",
      "2022-04-11 12:36:13.898019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 650 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:86:00.0, compute capability: 8.6\n",
      "2022-04-11 12:36:13.899032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 9687 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:af:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['标准', '美国', '科幻', '大片', '。', '参考', '影片', '《', '世界末日', ' ', 'Armageddon', ' ', '(', '1998', ')', '》']\n",
      "[1276, 258, 521, 1250, 6, 3912, 125, 23, 2, 2, 2, 2, 2, 2, 2, 24]\n"
     ]
    }
   ],
   "source": [
    "with open(DATA_W2V_VECTOR_PATH, 'r') as vf:\n",
    "    with open(DATA_W2V_META_PATH, 'r') as mf:\n",
    "        w2v_vector = np.loadtxt(vf)\n",
    "        w2v_meta = pd.read_csv(mf, sep='\\t', header=None)\n",
    "\n",
    "word2index = dict([(row[0], idx + 3) for idx, row in w2v_meta.iterrows()])\n",
    "word2index['<PAD>'] = 0\n",
    "word2index['<START>'] = 1\n",
    "word2index['<UNK>'] = 2\n",
    "word2index['<UNUSED>'] = 3\n",
    "\n",
    "index2word = dict([(i, w) for w, i in word2index.items()])\n",
    "\n",
    "def decode_review(seq):\n",
    "    return ' '.join([index2word.get(i, '?') for i in seq])\n",
    "\n",
    "def encode_review(words):\n",
    "    return [word2index.get(w, 2) for w in words]\n",
    "\n",
    "\n",
    "text_sequences = pickle.load(open(DATA_TEXT_SEQUENCES_PATH, 'rb'))\n",
    "labels = pickle.load(open(DATA_LABELS_PATH, 'rb'))\n",
    "\n",
    "print(text_sequences[0])\n",
    "print(encode_review(text_sequences[0]))\n",
    "# print(decode_review(sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4102, 128) 4102 128\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2index) + 3\n",
    "vector_length = len(w2v_vector[0])\n",
    "\n",
    "embeddings_matrix = np.array([np.zeros(vector_length) for _ in range(3)] + [w2v_vector[i - 3] for w, i in word2index.items()])\n",
    "\n",
    "print(embeddings_matrix.shape, vocab_size, vector_length)\n",
    "\n",
    "# embeddings_matrix = embeddings_matrix.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(text_sequences) == len(labels))\n",
    "\n",
    "val_size = 0.25\n",
    "\n",
    "idx = list(range(len(labels)))\n",
    "\n",
    "random.shuffle(idx)\n",
    "\n",
    "dataset_train_idx, dataset_val_idx = idx[int(val_size * len(idx)):], idx[:int(val_size * len(idx))]\n",
    "\n",
    "train_data = [[word2index.get(w, 0) for w in text_sequences[i]] for i in dataset_train_idx]\n",
    "val_data = [[word2index.get(w, 0) for w in text_sequences[i]] for i in dataset_val_idx]\n",
    "\n",
    "train_labels = [labels[i] for i in dataset_train_idx]\n",
    "val_labels = [labels[i] for i in dataset_val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 128\n",
    "\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        value=word2index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "val_data = keras.preprocessing.sequence.pad_sequences(val_data,\n",
    "                                                      value=word2index[\"<PAD>\"],\n",
    "                                                      padding='post',\n",
    "                                                      maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = np.array(train_data).astype(np.int32)\n",
    "val_data = np.array(val_data).astype(np.int32)\n",
    "\n",
    "train_labels = np.array(train_labels).astype(np.float32)\n",
    "val_labels = np.array(val_labels).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  12  189   80   62   81    0  220    0    0    0    5   88    0    0\n",
      "  108   26    0    0 1891    5   27    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 2. 3. ... 2. 4. 3.]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 128, 128)          525056    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 624,001\n",
      "Trainable params: 98,945\n",
      "Non-trainable params: 525,056\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "embedding_layer = keras.layers.Embedding(vocab_size,\n",
    "                            vector_length, \n",
    "                            weights=[embeddings_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False\n",
    "                            )\n",
    "\n",
    "\n",
    "model.add(embedding_layer)\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "# model.add(keras.layers.Dense(vector_length, activation='relu'))\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 6.3350 - accuracy: 0.0414     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 12:36:18.680490: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 2s 11ms/step - loss: 5.9323 - accuracy: 0.0445 - val_loss: 2.9261 - val_accuracy: 0.0516\n",
      "Epoch 2/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.7053 - accuracy: 0.0578 - val_loss: 1.1538 - val_accuracy: 0.0516\n",
      "Epoch 3/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.1381 - accuracy: 0.0578 - val_loss: 1.0922 - val_accuracy: 0.0516\n",
      "Epoch 4/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.1048 - accuracy: 0.0578 - val_loss: 1.0903 - val_accuracy: 0.0516\n",
      "Epoch 5/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0971 - accuracy: 0.0578 - val_loss: 1.0859 - val_accuracy: 0.0516\n",
      "Epoch 6/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0945 - accuracy: 0.0578 - val_loss: 1.1074 - val_accuracy: 0.0516\n",
      "Epoch 7/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0944 - accuracy: 0.0578 - val_loss: 1.0823 - val_accuracy: 0.0516\n",
      "Epoch 8/40\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.0894 - accuracy: 0.0578 - val_loss: 1.0830 - val_accuracy: 0.0516\n",
      "Epoch 9/40\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.0878 - accuracy: 0.0578 - val_loss: 1.0826 - val_accuracy: 0.0516\n",
      "Epoch 10/40\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.0878 - accuracy: 0.0578 - val_loss: 1.0852 - val_accuracy: 0.0516\n",
      "Epoch 11/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0876 - accuracy: 0.0578 - val_loss: 1.0877 - val_accuracy: 0.0516\n",
      "Epoch 12/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0895 - accuracy: 0.0578 - val_loss: 1.0840 - val_accuracy: 0.0516\n",
      "Epoch 13/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0837 - accuracy: 0.0578 - val_loss: 1.0825 - val_accuracy: 0.0516\n",
      "Epoch 14/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0838 - accuracy: 0.0578 - val_loss: 1.0825 - val_accuracy: 0.0516\n",
      "Epoch 15/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0791 - accuracy: 0.0578 - val_loss: 1.0866 - val_accuracy: 0.0516\n",
      "Epoch 16/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0823 - accuracy: 0.0578 - val_loss: 1.0843 - val_accuracy: 0.0516\n",
      "Epoch 17/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0770 - accuracy: 0.0578 - val_loss: 1.0836 - val_accuracy: 0.0516\n",
      "Epoch 18/40\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 1.0804 - accuracy: 0.0578 - val_loss: 1.0874 - val_accuracy: 0.0516\n",
      "Epoch 19/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0728 - accuracy: 0.0578 - val_loss: 1.0854 - val_accuracy: 0.0516\n",
      "Epoch 20/40\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.0763 - accuracy: 0.0578 - val_loss: 1.0837 - val_accuracy: 0.0516\n",
      "Epoch 21/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0711 - accuracy: 0.0578 - val_loss: 1.0958 - val_accuracy: 0.0516\n",
      "Epoch 22/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0671 - accuracy: 0.0578 - val_loss: 1.0987 - val_accuracy: 0.0516\n",
      "Epoch 23/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0670 - accuracy: 0.0578 - val_loss: 1.0830 - val_accuracy: 0.0516\n",
      "Epoch 24/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0627 - accuracy: 0.0578 - val_loss: 1.0852 - val_accuracy: 0.0516\n",
      "Epoch 25/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0616 - accuracy: 0.0578 - val_loss: 1.0875 - val_accuracy: 0.0516\n",
      "Epoch 26/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0601 - accuracy: 0.0578 - val_loss: 1.0880 - val_accuracy: 0.0516\n",
      "Epoch 27/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0579 - accuracy: 0.0578 - val_loss: 1.0888 - val_accuracy: 0.0516\n",
      "Epoch 28/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0560 - accuracy: 0.0578 - val_loss: 1.1014 - val_accuracy: 0.0516\n",
      "Epoch 29/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0503 - accuracy: 0.0578 - val_loss: 1.0870 - val_accuracy: 0.0516\n",
      "Epoch 30/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0459 - accuracy: 0.0578 - val_loss: 1.0888 - val_accuracy: 0.0516\n",
      "Epoch 31/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0474 - accuracy: 0.0578 - val_loss: 1.1077 - val_accuracy: 0.0516\n",
      "Epoch 32/40\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.0447 - accuracy: 0.0578 - val_loss: 1.0957 - val_accuracy: 0.0516\n",
      "Epoch 33/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0367 - accuracy: 0.0578 - val_loss: 1.0949 - val_accuracy: 0.0516\n",
      "Epoch 34/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0360 - accuracy: 0.0578 - val_loss: 1.0947 - val_accuracy: 0.0516\n",
      "Epoch 35/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0304 - accuracy: 0.0578 - val_loss: 1.0945 - val_accuracy: 0.0516\n",
      "Epoch 36/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0280 - accuracy: 0.0578 - val_loss: 1.0986 - val_accuracy: 0.0516\n",
      "Epoch 37/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0280 - accuracy: 0.0578 - val_loss: 1.1017 - val_accuracy: 0.0516\n",
      "Epoch 38/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0195 - accuracy: 0.0578 - val_loss: 1.1018 - val_accuracy: 0.0516\n",
      "Epoch 39/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0129 - accuracy: 0.0578 - val_loss: 1.1096 - val_accuracy: 0.0516\n",
      "Epoch 40/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0099 - accuracy: 0.0578 - val_loss: 1.1750 - val_accuracy: 0.0516\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                    train_labels,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(val_data, val_labels),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 - 0s - loss: 1.1750 - accuracy: 0.0516 - 427ms/epoch - 2ms/step\n",
      "[1.1750140190124512, 0.051595259457826614]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(val_data,  val_labels, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAkY0lEQVR4nO3de5wU9Znv8c/DMDAMwyXcFBlgIBGJCMzAAFEU0WQ3Ki6iognLESckomwSb0kMaowkWc6ek7A5LhvJBjVodAyaRIl3jQKiMVEHJAiKUQwIiggoN7kN8Jw/qmZohu6eYWZquqn5vl+vfnV1XX71dHX3U7/6VfWvzN0REZH4aZHpAEREJBpK8CIiMaUELyISU0rwIiIxpQQvIhJTSvAiIjGlBC91YmZPmtnljT1vJpnZGjP7UgTlupl9Lhz+HzO7pS7z1mM9E83smfrGmabc0Wa2vrHLlabXMtMBSHTMbGfCy3xgL3AgfH2lu5fXtSx3PzeKeePO3a9qjHLMrAj4B5Dr7vvDssuBOn+G0vwowceYuxdUDZvZGuAb7v5szfnMrGVV0hCR+FATTTNUdQhuZt83sw+BuWb2GTN7zMw2mdkn4XBhwjKLzOwb4XCZmb1oZjPDef9hZufWc94+ZrbYzHaY2bNmdruZ3Zci7rrE+BMz+3NY3jNm1iVh+mVmttbMtpjZzWm2zwgz+9DMchLGXWhmy8Ph4Wb2FzPbamYbzOwXZtYqRVl3m9m/J7z+XrjMB2Y2uca8Y8zsNTPbbmbrzGx6wuTF4fNWM9tpZqdWbduE5U8zs1fNbFv4fFpdt006Zvb5cPmtZrbSzMYmTDvPzN4Iy3zfzL4bju8Sfj5bzexjM3vBzJRvmpg2ePN1PNAJ6A1MIfguzA1f9wJ2A79Is/wI4C2gC/BT4C4zs3rMez/wCtAZmA5clmaddYnxX4GvAd2AVkBVwjkZ+GVY/gnh+gpJwt1fBj4Fzq5R7v3h8AHguvD9nAp8Efi3NHETxnBOGM8/AScCNdv/PwUmAR2BMcBUMxsXThsVPnd09wJ3/0uNsjsBjwOzwvf2c+BxM+tc4z0csW1qiTkXeBR4Jlzu20C5mZ0UznIXQXNfO+AUYEE4/jvAeqArcBxwE6B+UZqYEnzzdRC41d33uvtud9/i7n9w913uvgOYAZyZZvm17n6Hux8A7gG6E/yQ6zyvmfUChgE/dPd97v4i8EiqFdYxxrnu/nd33w08CBSH48cDj7n7YnffC9wSboNUfgtMADCzdsB54TjcfYm7/9Xd97v7GuBXSeJI5tIwvhXu/inBDi3x/S1y99fd/aC7Lw/XV5dyIdghvO3u94Zx/RZYBfxLwjyptk06XwAKgP8TfkYLgMcItw1QCZxsZu3d/RN3X5owvjvQ290r3f0FV8dXTU4Jvvna5O57ql6YWb6Z/SpswthO0CTQMbGZooYPqwbcfVc4WHCU854AfJwwDmBdqoDrGOOHCcO7EmI6IbHsMMFuSbUugtr6RWbWGrgIWOrua8M4+oXNDx+Gcfxvgtp8bQ6LAVhb4/2NMLOFYRPUNuCqOpZbVfbaGuPWAj0SXqfaNrXG7O6JO8PEci8m2PmtNbPnzezUcPzPgHeAZ8zsXTObVre3IY1JCb75qlmb+g5wEjDC3dtzqEkgVbNLY9gAdDKz/IRxPdPM35AYNySWHa6zc6qZ3f0NgkR2Loc3z0DQ1LMKODGM46b6xEDQzJTofoIjmJ7u3gH4n4Rya6v9fkDQdJWoF/B+HeKqrdyeNdrPq8t191fd/QKC5pv5BEcGuPsOd/+Ou/cFxgLXm9kXGxiLHCUleKnSjqBNe2vYnntr1CsMa8QVwHQzaxXW/v4lzSINifH3wPlmdnp4QvTH1P79vx+4hmBH8rsacWwHdppZf2BqHWN4ECgzs5PDHUzN+NsRHNHsMbPhBDuWKpsImpT6pij7CaCfmf2rmbU0s68AJxM0pzTEywS1/RvMLNfMRhN8RvPCz2yimXVw90qCbXIQwMzON7PPhedathGct0jXJCYRUIKXKrcBbYDNwF+Bp5povRMJTlRuAf4deIDgev1kbqOeMbr7SuCbBEl7A/AJwUnAdKrawBe4++aE8d8lSL47gDvCmOsSw5Phe1hA0HyxoMYs/wb82Mx2AD8krA2Hy+4iOOfw5/DKlC/UKHsLcD7BUc4W4Abg/BpxHzV330eQ0M8l2O6zgUnuviqc5TJgTdhUdRXB5wnBSeRngZ3AX4DZ7r6wIbHI0TOd95BsYmYPAKvcPfIjCJG4Uw1eMsrMhpnZZ82sRXgZ4QUEbbki0kD6J6tk2vHAQwQnPNcDU939tcyGJBIPaqIREYkpNdGIiMRUVjXRdOnSxYuKijIdhojIMWPJkiWb3b1rsmlZleCLioqoqKjIdBgiIscMM6v5D+ZqaqIREYkpJXgRkZiKNMGbWUcz+72ZrTKzNxM6IhIRkYhF3Qb/X8BT7j4+7P8jv7YFRKTpVFZWsn79evbs2VP7zJJReXl5FBYWkpubW+dlIkvwZtaBoJOmMqju02JfVOsTkaO3fv162rVrR1FREanv1yKZ5u5s2bKF9evX06dPnzovF2UTTR+CHvDmhrchu9PM2jb2SsrLoagIWrQInst1C2KROtuzZw+dO3dWcs9yZkbnzp2P+kgrygTfEhgC/NLdSwhuR3ZEp/9mNsXMKsysYtOmTUe1gvJymDIF1q4F9+B5yhQleZGjoeR+bKjP5xRlgl8PrA/vbwlBf9xDas7k7nPcvdTdS7t2TXqtfko33wy7dh0+bteuYLyISHMXWYJ39w+BdQk35/0i8EZjruO9945uvIhkly1btlBcXExxcTHHH388PXr0qH69b1/6U3YVFRVcffXVta7jtNNOa5RYFy1axPnnn98oZTWVqK+iqboDeyvgXYI7ujeaXr2CZplk40Wk8ZWXB0fI770X/M5mzICJE2tfLpXOnTuzbNkyAKZPn05BQQHf/e53q6fv37+fli2Tp6nS0lJKS0trXcdLL71U/wCPcZFeB+/uy8Lml0HuPs7dP2nM8mfMgPwaF17m5wfjRaRxNdU5r7KyMq666ipGjBjBDTfcwCuvvMKpp55KSUkJp512Gm+99RZweI16+vTpTJ48mdGjR9O3b19mzZpVXV5BQUH1/KNHj2b8+PH079+fiRMnUtWb7hNPPEH//v0ZOnQoV199da019Y8//phx48YxaNAgvvCFL7B8+XIAnn/++eojkJKSEnbs2MGGDRsYNWoUxcXFnHLKKbzwwguNu8HSyKq+aI5WVc2hMWsUIpJcunNejf2bW79+PS+99BI5OTls376dF154gZYtW/Lss89y00038Yc//OGIZVatWsXChQvZsWMHJ510ElOnTj3imvHXXnuNlStXcsIJJzBy5Ej+/Oc/U1paypVXXsnixYvp06cPEyZMqDW+W2+9lZKSEubPn8+CBQuYNGkSy5YtY+bMmdx+++2MHDmSnTt3kpeXx5w5c/jyl7/MzTffzIEDB9hVcyNG6JhO8BB8sZTQRaLXlOe8LrnkEnJycgDYtm0bl19+OW+//TZmRmVlZdJlxowZQ+vWrWndujXdunVj48aNFBYWHjbP8OHDq8cVFxezZs0aCgoK6Nu3b/X15RMmTGDOnDlp43vxxRerdzJnn302W7ZsYfv27YwcOZLrr7+eiRMnctFFF1FYWMiwYcOYPHkylZWVjBs3juLi4oZsmqOivmhEpE5SnduK4pxX27aH/jJzyy23cNZZZ7FixQoeffTRlNeCt27duno4JyeH/fv312uehpg2bRp33nknu3fvZuTIkaxatYpRo0axePFievToQVlZGb/5zW8adZ3pKMGLSJ1k6pzXtm3b6NGjBwB33313o5d/0kkn8e6777JmzRoAHnjggVqXOeOMMygPTz4sWrSILl260L59e1avXs3AgQP5/ve/z7Bhw1i1ahVr167luOOO44orruAb3/gGS5cubfT3kIoSvIjUycSJMGcO9O4NZsHznDnRN5HecMMN3HjjjZSUlDR6jRugTZs2zJ49m3POOYehQ4fSrl07OnTokHaZ6dOns2TJEgYNGsS0adO45557ALjttts45ZRTGDRoELm5uZx77rksWrSIwYMHU1JSwgMPPMA111zT6O8hlay6J2tpaanrhh8iTefNN9/k85//fKbDyLidO3dSUFCAu/PNb36TE088keuuuy7TYR0h2edlZkvcPen1oqrBi0izd8cdd1BcXMyAAQPYtm0bV155ZaZDahTH/FU0IiINdd1112Vljb2hVIMXEYkpJXgRkZhSghcRiSkleBGRmFKCF5GMOeuss3j66acPG3fbbbcxderUlMuMHj2aqsupzzvvPLZu3XrEPNOnT2fmzJlp1z1//nzeeONQD+Y//OEPefbZZ48i+uSyqVthJXgRyZgJEyYwb968w8bNmzevTh1+QdALZMeOHeu17poJ/sc//jFf+tKX6lVWtlKCF5GMGT9+PI8//nj1zT3WrFnDBx98wBlnnMHUqVMpLS1lwIAB3HrrrUmXLyoqYvPmzQDMmDGDfv36cfrpp1d3KQzBNe7Dhg1j8ODBXHzxxezatYuXXnqJRx55hO9973sUFxezevVqysrK+P3vfw/Ac889R0lJCQMHDmTy5Mns3bu3en233norQ4YMYeDAgaxatSrt+8t0t8K6Dl5EALj2WgjvvdFoiovhtttST+/UqRPDhw/nySef5IILLmDevHlceumlmBkzZsygU6dOHDhwgC9+8YssX76cQYMGJS1nyZIlzJs3j2XLlrF//36GDBnC0KFDAbjooou44oorAPjBD37AXXfdxbe//W3Gjh3L+eefz/jx4w8ra8+ePZSVlfHcc8/Rr18/Jk2axC9/+UuuvfZaALp06cLSpUuZPXs2M2fO5M4770z5/jLdrbBq8CKSUYnNNInNMw8++CBDhgyhpKSElStXHtacUtMLL7zAhRdeSH5+Pu3bt2fs2LHV01asWMEZZ5zBwIEDKS8vZ+XKlWnjeeutt+jTpw/9+vUD4PLLL2fx4sXV0y+66CIAhg4dWt1BWSovvvgil112GZC8W+FZs2axdetWWrZsybBhw5g7dy7Tp0/n9ddfp127dmnLrgvV4EUESF/TjtIFF1zAddddx9KlS9m1axdDhw7lH//4BzNnzuTVV1/lM5/5DGVlZSm7Ca5NWVkZ8+fPZ/Dgwdx9990sWrSoQfFWdTnckO6Gp02bxpgxY3jiiScYOXIkTz/9dHW3wo8//jhlZWVcf/31TJo0qUGxqgYvIhlVUFDAWWedxeTJk6tr79u3b6dt27Z06NCBjRs38uSTT6YtY9SoUcyfP5/du3ezY8cOHn300eppO3bsoHv37lRWVlZ38QvQrl07duzYcURZJ510EmvWrOGdd94B4N577+XMM8+s13vLdLfCqsGLSMZNmDCBCy+8sLqppqp73f79+9OzZ09GjhyZdvkhQ4bwla98hcGDB9OtWzeGDRtWPe0nP/kJI0aMoGvXrowYMaI6qX/1q1/liiuuYNasWdUnVwHy8vKYO3cul1xyCfv372fYsGFcddVV9XpfVfeKHTRoEPn5+Yd1K7xw4UJatGjBgAEDOPfcc5k3bx4/+9nPyM3NpaCgoFFuDKLugkWaMXUXfGxRd8EiIgIowYuIxJYSvEgzl03NtJJafT4nJXiRZiwvL48tW7YoyWc5d2fLli3k5eUd1XK6ikakGSssLGT9+vVs2rQp06FILfLy8igsLDyqZZTgRZqx3Nxc+vTpk+kwJCJqohERiSkleBGRmFKCFxGJKSV4EZGYUoIXEYmpSK+iMbM1wA7gALA/VX8JIiLS+JriMsmz3H1zE6xHREQSqIlGRCSmok7wDjxjZkvMbEqyGcxsiplVmFmF/k0nItJ4ok7wp7v7EOBc4JtmNqrmDO4+x91L3b20a9euEYcjItJ8RJrg3f398Pkj4GFgeJTrExGRQyJL8GbW1szaVQ0D/wysiGp9IiJyuCivojkOeNjMqtZzv7s/FeH6REQkQWQJ3t3fBQZHVb6IiKSnyyRFRGJKCV5EJKaU4EVEYkoJXkQkppTgRURiSgleRCSmlOBFRGJKCV5EJKaU4EVEYkoJXkQkppTgRURiSgleRCSmlOBFRGJKCV5EJKaU4EVEYkoJXkQkppTgRURiSgleRCSmlOBFRGJKCV5EJKaU4EVEYkoJXkQkppTgRURiSgleRCSmlOBFRGJKCV5EJKaU4EVEYkoJXkQkppTgRURiSgleRCSmlOBFRGIq8gRvZjlm9pqZPRb1ukRE5JCmqMFfA7zZBOsREZEEkSZ4MysExgB3RrkeERE5UtQ1+NuAG4CDqWYwsylmVmFmFZs2bYo4HBGR5iOyBG9m5wMfufuSdPO5+xx3L3X30q5du0YVjohIsxNlDX4kMNbM1gDzgLPN7L4I1yciIgkiS/DufqO7F7p7EfBVYIG7/6+o1iciIofTdfAiIjHVsilW4u6LgEVNsS4REQmoBi8iElNK8CIiMaUELyISU0rwIiIxpQQvIhJTSvAiIjGlBC8iElN1SvBm1tbMWoTD/cxsrJnlRhuaiIg0RF1r8IuBPDPrATwDXAbcHVVQIiLScHVN8Obuu4CLgNnufgkwILqwRESkoeqc4M3sVGAi8Hg4LieakEREpDHUNcFfC9wIPOzuK82sL7AwsqhERKTB6tTZmLs/DzwPEJ5s3ezuV0cZmIiINExdr6K538zam1lbYAXwhpl9L9rQRESkIeraRHOyu28HxgFPAn0IrqQREZEsVdcEnxte9z4OeMTdKwGPLCoREWmwuib4XwFrgLbAYjPrDWyPKigREWm4up5knQXMShi11szOiiYkERFpDHU9ydrBzH5uZhXh4z8JavMiIpKl6tpE82tgB3Bp+NgOzI0qKBERabi63nT7s+5+ccLrH5nZsgjiERGRRlLXGvxuMzu96oWZjQR2RxOSiIg0hrrW4K8CfmNmHcLXnwCXRxOSiIg0hrpeRfM3YLCZtQ9fbzeza4HlEcYmIiINcFR3dHL37eE/WgGujyAeERFpJA25ZZ81WhQiItLoGpLg1VWBiEgWS9sGb2Y7SJ7IDWgTSUQiItIo0iZ4d2/XVIGIiEjjakgTjYiIZDEleBGRmIoswZtZnpm9YmZ/M7OVZvajqNYlIiJHqus/WetjL3C2u+8Mbxbyopk96e5/jXCdIiISiizBu7sDO8OXueFDl1aKiDSRSNvgzSwn7HXyI+BP7v5yknmmVPUzv2nTpijDERFpViJN8O5+wN2LgUJguJmdkmSeOe5e6u6lXbt2jTIcEZFmpUmuonH3rcBC4JzGLvvgQTjzTPjv/27skkVEjm1RXkXT1cw6hsNtgH8CVjX2elq0gLfeguXq11JE5DBRXkXTHbjHzHIIdiQPuvtjUayosBDWr4+iZBGRY1eUV9EsB0qiKj9RYSGsXt0UaxIROXbE4p+sqsGLiBwpNgl+61bYubPWWUVEmo3YJHiA99/PbBwiItkkFgm+Z8/gWc00IiKHxCLBV9XgleBFRA6JRYLv0SN4VoIXETkkFgk+Lw+6dFGCFxFJFIsED7pUUkSkplgl+HXrMh2FiEj2iFWCVw1eROSQWCX4LVtg9+5MRyIikh1ileBBf3YSEakSuwSvZhoRkYASvIhITMUmwevPTiIih4tNgi8ogI4dleBFRKrEJsFD0OmYEryISCBWCV7XwouIHKIELyISU7FL8Bs3wr59mY5ERCTzYpfgAT74ILNxiIhkg1gmeDXTiIgowYuIxFYsE7y6DRYRiVmCb98e2rVTDV5EBGKW4EGXSoqIVFGCFxGJKSV4EZGYimWC37ABKiszHYmISGbFMsG7w4cfZjoSEZHMil2C79kzeFYzjYg0d5EleDPraWYLzewNM1tpZtdEta5E+rOTiEigZYRl7we+4+5LzawdsMTM/uTub0S4TiV4EZFQZDV4d9/g7kvD4R3Am0CPqNZXpWNHyM9XghcRaZI2eDMrAkqAl5NMm2JmFWZWsWnTpkZYly6VFBGBJkjwZlYA/AG41t2315zu7nPcvdTdS7t27doo61SCFxGJOMGbWS5Bci9394eiXFciJXgRkWivojHgLuBNd/95VOtJprAQ3n8fDhxoyrWKiGSXKGvwI4HLgLPNbFn4OC/C9VUrLAyS+8aNTbE2EZHsFNllku7+ImBRlZ9O4qWSJ5yQiQhERDIvdv9kBV0LLyICSvAiIrEVywTfpQu0bq0ELyLNWywTfOKfncrLoagIWrQInsvLMx2diEjTiLIvmowqLISlS+GPf4Rdu4Jxa9fClCnB8MSJmYtNRKQpxLIGD0GCX736UHKvsmsX3HxzZmISEWlKsU7w+/cnn/bee00bi4hIJsQ6wafSq1fTxSEikimxT/B5eYePz8+HGTOaPh4RkaYW+wQ/dSr07h1cWdO7N8yZoxOsItI8xPoqGoDPfQ7WrMloKCIiGRHbGny3btCypf7sJCLNV2wTfIsW0KMHrFuX6UhERDIjtgkedOMPEWnelOBFRGKqWSR490xHIiLS9GKf4PfsgY8/znQkIiJNL9YJvmfP4FnNNCLSHMU6wevGHyLSnCnBi4jEVKwT/PHHQ06OEryINE+xTvA5OdC9uxK8iDRPsU7woGvhRaT5UoIXEYmpZpHg163Tn51EpPlpFgn+009h+/ZMRyIi0rSaRYKH5M005eVQVBT0PFlUFLwWEWkq+/bBE0/ArFnRlN9sEvzvfgeffHJofHk5TJkCa9cGzTdr1wavE5N8bTsA7SBE5GhVVsJTT8HkyXDccTBmDPzHfwTjG527Z81j6NCh3tg++cS9b193cG/Z0v1LX3K//Xb3Hj2CcTUfvXsHy913n3t+/uHT8vOD8XWZXjVP797uZsFz4rTapjdk2ainK7bU00WSqax0f/pp969/3b1TpyBftG/vPmmS+2OPue/dW/+ygQpPkVPNs+jsY2lpqVdUVDR6uQcPQkUFPPxw8HjrrfTzv/8+jBiRvFmnd+/gFoBFRUGtv6Zu3YKbej/xBDzyCBw4cGhabi5ce22w5/7LX+Bb34Jduw5Nz88P7hkLwdFEsmkTJx46+sjE9OYY2+zZQS3rnnvg5pth795D01u1giuugFNPhf374cUX4aGHgg7uunULPu+yMujSBR58MFj+vfegV6/ge5J4f+Dy8min33ffoek9egT3Kz7ttODIdutWeO45ePxx2LYNOncO4h4/Hjp1ggULglrmunWp133TTUHZJ5wQfMdPOQU2bAgeL70U/Ab37Am26fDhUFoKHTseenToEPxGzNI/0qk5PfH1wYNBLXnfvuA5cXjfvuDzS/WorEx/ocbBg7B7d/DdqXp8+umh4ffeC74TBQVwwQVw6aXw5S9D69bp309dmNkSdy9NOq05JPia3nwz+GJv3Vq/5Vu3PvxH3piqPvBk5bduHfwoKiqST2/VCvr3D95fssO9Fi2CH+vHHwdfyJpycoIO2tavD77UycqH4MeQLLYRI+Dll5PHlpsLffvC6tXJy87JCRLHunXJp+fmwoABsHJl8veWkxM8J+5Qq7RoAV27wubNyae3bAn9+sHbb0d0mJxCixbB9m7fPvhMPvjg8CRiFkxr1SpIHjt3HllGbm5QTlXyqsksuivIqpLx/v3Jv09VcnKC6TXfW25u8u9StmvZMtjmicygTZtg55WfD23bHhrOzw928GPHBkm9TZvGjSddgo+sDd7Mfm1mH5nZiqjWUV+f/zz84hfBhk/UqhV8/evwq18FiTCZDh2CWlm7dsmnH3dc7Tf5vvfe1NP27k2989i7N/3OZd8+6NMndZI6eBAuuST1j/HAATjjjOQJtqr8VD/IvXuDL32q2Corobg4ddkHDsDIkamnV1YGO4BU7+3AgeTJG4L3O25c6un798PJJ6dP7rWdBPv734OaazKdOgXfm2RxffQRfPazQS26ZiJ2D2K++OLUNdc2beCaa1Injfbt4ZZbkq8fgu/ra68FNfpkunULavOp1n399UGtNJnu3YOdao8eyd9b9+7B92X2bMjLO3x669ZB3IsXB0cdNWu6rVsHRww33ZR82o03wrPPwrRpyaf/5Cfw+uvw058eue42beDOO4Ojjd/85sht26oV/PrXh36rv/510C3Ktm3BTmv6dFi2LDhq+drXYPlyuPvuIG889NDhZUV+Hi9V201DH8AoYAiwoq7LRNEGn05tbbkNaYPv3Tt9G3+66Q1ZNurpii31dLPk083ST6tt2UxPj3rdx/Jnni4PNMZ5vLogTRt80pGN9QCKsjnB16ahJ/vq++E29IsR5XTFlnp6NieibE6i2bzzacjOqaHbpa6yOsEDU4AKoKJXr15H986y3LF8NYhia9ydeqZ3Ptm848zmnU8mj9rqKqsTfOIj22rwIkcrW3c+DZ2eqR1jbdMzvWNUDV4JXkRqka07n7qsW23wSvAiElNR7nzqIl2Cj+w6eDP7LTAa6AJsBG5197vSLdNU18GLiMRFuuvgW0a1UnefEFXZIiJSu9h3NiYi0lwpwYuIxJQSvIhITCnBi4jEVFb1Jmlmm4AknfACwdU4m5swnKOh2OpHsdWPYqufuMbW2927JpuQVQk+HTOrSHUpUKYptvpRbPWj2OqnOcamJhoRkZhSghcRialjKcHPyXQAaSi2+lFs9aPY6qfZxXbMtMGLiMjROZZq8CIichSU4EVEYirrE7yZnWNmb5nZO2Y2LdPx1GRma8zsdTNbZmYZ7Qoz2Y3OzayTmf3JzN4Onz+TRbFNN7P3w223zMzOy1BsPc1soZm9YWYrzeyacHxGt12auLJlu+WZ2Stm9rcwvh+F4/uY2cvhb/YBM2uVRbHdbWb/SNh2xU0dWxhHjpm9ZmaPha+j2Wap+hHOhgeQA6wG+gKtgL8BJ2c6rhoxrgG6ZDqOMJYjbnQO/BSYFg5PA/5vFsU2HfhuFmy37sCQcLgd8Hfg5ExvuzRxZct2M6AgHM4FXga+ADwIfDUc/z/A1CyK7W5gfBZsu+uB+4HHwteRbLNsr8EPB95x93fdfR8wD7ggwzFlLXdfDHxcY/QFwD3h8D3AuKaMqUqK2LKCu29w96Xh8A7gTaAHGd52aeLKCh7YGb7MDR8OnA38Phyfke9cmtgyzswKgTHAneFrI6Jtlu0JvgewLuH1erLoCx5y4BkzW2JmUzIdTBLHufuGcPhD4LhMBpPEt8xsediEk5Hmo0RmVgSUENT4smbb1YgLsmS7hU0Ny4CPgD8RHHFvdff94SwZ+83WjM3dq7bdjHDb/T8za52B0G4DbgAOhq87E9E2y/YEfyw43d2HAOcC3zSzUZkOKBUPjv+yohYT+iXwWaAY2AD8ZyaDMbMC4A/Ate6+PXFaJrddkriyZru5+wF3LwYKCY64+2cqlppqxmZmpwA3EsQ4DOgEfL8pYzKz84GP3H1JU6wv2xP8+0DPhNeF4bis4e7vh88fAQ8TfMmzyUYz6w4QPn+U4XiqufvG8Ed4ELiDDG47M8slSKLl7v5QODrj2y5ZXNm03aq4+1ZgIXAq0NHMqu4Wl/HfbEJs54TNXu7ue4G5NP22GwmMNbM1BE3OZwP/RUTbLNsT/KvAieEZ5lbAV4FHMhxTNTNra2btqoaBfwZWpF+qyT0CXB4OXw78MYOxHKYqeYYuJEPbLmwDvQt4091/njApo9suVVxZtN26mlnHcLgN8E8E5wkWAuPD2TLynUsR26qEHbYRtHM36bZz9xvdvdDdiwjy2QJ3n0hU2yzTZ5PrcLb5PIKrB1YDN2c6nhqx9SW4sudvwMpMxwf8luCQvZKgHe/rBO17zwFvA88CnbIotnuB14HlBMm0e4ZiO52g+WU5sCx8nJfpbZcmrmzZboOA18I4VgA/DMf3BV4B3gF+B7TOotgWhNtuBXAf4ZU2Gdp+ozl0FU0k20xdFYiIxFS2N9GIiEg9KcGLiMSUEryISEwpwYuIxJQSvIhITCnBS+yZ2YGE3gOXWSP2SmpmRYk9ZIpkk5a1zyJyzNvtwV/WRZoV1eCl2bKgL/+fWtCf/ytm9rlwfJGZLQg7pHrOzHqF448zs4fDPsb/ZmanhUXlmNkdYb/jz4T/nMTMrg77cl9uZvMy9DalGVOCl+agTY0mmq8kTNvm7gOBXxD08gfw38A97j4IKAdmheNnAc+7+2CCvu1XhuNPBG539wHAVuDicPw0oCQs56po3ppIavonq8Seme1094Ik49cAZ7v7u2GnXh+6e2cz20zw9//KcPwGd+9iZpuAQg86qqoqo4igK9oTw9ffB3Ld/d/N7ClgJzAfmO+H+icXaRKqwUtz5ymGj8behOEDHDq3NQa4naC2/2pCb4EiTUIJXpq7ryQ8/yUcfomgpz+AicAL4fBzwFSovplEh1SFmlkLoKe7LyToc7wDcMRRhEiUVKOQ5qBNeGefKk+5e9Wlkp8xs+UEtfAJ4bhvA3PN7HvAJuBr4fhrgDlm9nWCmvpUgh4yk8kB7gt3AgbM8qBfcpEmozZ4abbCNvhSd9+c6VhEoqAmGhGRmFINXkQkplSDFxGJKSV4EZGYUoIXEYkpJXgRkZhSghcRian/D2Wld5FLdIo/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "798719e834ce2667b284169792ed9be744f500b1bbad4a58ecba241c6661f77e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('news')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
